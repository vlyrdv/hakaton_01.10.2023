{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, RepeatVector, concatenate\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "25\n",
      "(360, 640, 3)\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"lstm_8\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 360, 640, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/vlyrdv/Desktop/hack/gpt.ipynb Cell 2\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vlyrdv/Desktop/hack/gpt.ipynb#W1sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m max_caption_length \u001b[39m=\u001b[39m captions_seq_padded\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vlyrdv/Desktop/hack/gpt.ipynb#W1sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m num_words \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(tokenizer\u001b[39m.\u001b[39mword_index) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vlyrdv/Desktop/hack/gpt.ipynb#W1sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m model \u001b[39m=\u001b[39m create_model(max_video_length, max_caption_length, num_words)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vlyrdv/Desktop/hack/gpt.ipynb#W1sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vlyrdv/Desktop/hack/gpt.ipynb#W1sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m model\u001b[39m.\u001b[39mfit([videos, captions_seq_padded[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]], np\u001b[39m.\u001b[39mexpand_dims(captions_seq_padded[:, \u001b[39m1\u001b[39m:], axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m)\n",
      "\u001b[1;32m/Users/vlyrdv/Desktop/hack/gpt.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vlyrdv/Desktop/hack/gpt.ipynb#W1sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m input_video \u001b[39m=\u001b[39m Input((\u001b[39m360\u001b[39m, \u001b[39m640\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vlyrdv/Desktop/hack/gpt.ipynb#W1sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m input_caption \u001b[39m=\u001b[39m Input(shape\u001b[39m=\u001b[39m(max_caption_length))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vlyrdv/Desktop/hack/gpt.ipynb#W1sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m video_encoder \u001b[39m=\u001b[39m LSTM(\u001b[39m256\u001b[39;49m)(input_video)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vlyrdv/Desktop/hack/gpt.ipynb#W1sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m caption_encoder \u001b[39m=\u001b[39m Embedding(num_words, \u001b[39m256\u001b[39m, mask_zero\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(input_caption)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vlyrdv/Desktop/hack/gpt.ipynb#W1sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m caption_encoder \u001b[39m=\u001b[39m LSTM(\u001b[39m256\u001b[39m)(caption_encoder)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/rnn/base_rnn.py:556\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m inputs, initial_state, constants \u001b[39m=\u001b[39m rnn_utils\u001b[39m.\u001b[39mstandardize_args(\n\u001b[1;32m    552\u001b[0m     inputs, initial_state, constants, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_constants\n\u001b[1;32m    553\u001b[0m )\n\u001b[1;32m    555\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 556\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    558\u001b[0m \u001b[39m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[39m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39m# input_spec to include them.\u001b[39;00m\n\u001b[1;32m    562\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/input_spec.py:235\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    233\u001b[0m     ndim \u001b[39m=\u001b[39m shape\u001b[39m.\u001b[39mrank\n\u001b[1;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39m!=\u001b[39m spec\u001b[39m.\u001b[39mndim:\n\u001b[0;32m--> 235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    237\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m, found ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m         )\n\u001b[1;32m    241\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mmax_ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"lstm_8\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 360, 640, 3)"
     ]
    }
   ],
   "source": [
    "video_folder = '/Users/vlyrdv/Desktop/hack/rutube_hackathon_novosibirsk/train/train_video'\n",
    "caption_folder = '/Users/vlyrdv/Desktop/hack/rutube_hackathon_novosibirsk/train/train_stt'\n",
    "\n",
    "# Загрузка видео и описаний\n",
    "video_files = os.listdir(video_folder)\n",
    "caption_files = os.listdir(caption_folder)\n",
    "\n",
    "videos = []\n",
    "captions = []\n",
    "\n",
    "for video_file in video_files:\n",
    "    video_path = os.path.join(video_folder, video_file)\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    count = 0\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if count % 60 == 0:\n",
    "            frames.append(frame)\n",
    "        if not ret:\n",
    "            break\n",
    "        if len(frames) >= 25:\n",
    "            videos.append(frames)\n",
    "            break\n",
    " \n",
    "video.release()\n",
    "print(len(videos))\n",
    "print(len(videos[0]))\n",
    "print(videos[0][0].shape)\n",
    "print()\n",
    "\n",
    "\n",
    "for caption_file in caption_files:\n",
    "    caption_path = os.path.join(caption_folder, caption_file)\n",
    "    with open(caption_path, 'r') as f:\n",
    "        caption = f.read()\n",
    "        captions.append(caption)\n",
    "\n",
    "# Предобработка данных\n",
    "def preprocess_data(videos, captions):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(captions)\n",
    "    captions_seq = tokenizer.texts_to_sequences(captions)\n",
    "\n",
    "    max_len = max(len(seq) for seq in captions_seq)\n",
    "    captions_seq_padded = pad_sequences(captions_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "    return np.array(videos), captions_seq_padded, tokenizer\n",
    "\n",
    "videos, captions_seq_padded, tokenizer = preprocess_data(videos, captions)\n",
    "\n",
    "def create_model(max_video_length, max_caption_length, num_words):\n",
    "    input_video = Input((360, 640, 3))\n",
    "    input_caption = Input(shape=(max_caption_length))\n",
    "\n",
    "    video_encoder = LSTM(256)(input_video)\n",
    "\n",
    "    caption_encoder = Embedding(num_words, 256, mask_zero=True)(input_caption)\n",
    "    caption_encoder = LSTM(256)(caption_encoder)\n",
    "\n",
    "    decoder = Dense(256, activation=\"relu\")(video_encoder)\n",
    "    decoder = RepeatVector(max_caption_length)(decoder)\n",
    "    decoder = concatenate([decoder, caption_encoder])\n",
    "    decoder = LSTM(512, video[0].shape, return_sequences=True)(decoder)\n",
    "    decoder = Dense(num_words, activation=\"softmax\")(decoder)\n",
    "\n",
    "    model = Model(inputs=[input_video, input_caption], outputs=decoder)\n",
    "    return model\n",
    "\n",
    "max_video_length = 25\n",
    "max_caption_length = captions_seq_padded.shape[1]\n",
    "num_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "\n",
    "model = create_model(max_video_length, max_caption_length, num_words)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit([videos, captions_seq_padded[:, :-1]], np.expand_dims(captions_seq_padded[:, 1:], axis=-1), epochs=10, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
